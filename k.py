import os
import logging
import asyncio
import aiohttp
import tempfile
from typing import List, Dict, Optional
from datetime import datetime

from aiogram import Bot, Dispatcher, types
from aiogram.dispatcher import FSMContext
from aiogram.dispatcher.filters import Command
from aiogram.contrib.fsm_storage.memory import MemoryStorage
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.utils import executor

import openai
import numpy as np
import faiss

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(name)s: %(message)s"
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
ADMIN_IDS = [797671728]  # —Ç–≤–æ–π Telegram ID
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
KNOWLEDGE_BASE_PATH = os.getenv("KNOWLEDGE_BASE_PATH", "knowledge_base.txt")
DOCS_DIR = "knowledge_base"

BOT_PERSONA = os.getenv("BOT_PERSONA", """–¢—ã ‚Äî –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è –ø–æ–¥—Ä—É–∂–∫–∞ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª—è –¥–µ–≤—É—à–µ–∫.

–¢–≤–æ—è —Ä–æ–ª—å ‚Äî –≤—ã—Å–ª—É—à–∏–≤–∞—Ç—å, –ø–æ–¥–±–∞–¥—Ä–∏–≤–∞—Ç—å, –ø–æ–º–æ–≥–∞—Ç—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —ç–º–æ—Ü–∏—è—Ö –∏ –¥–∞–≤–∞—Ç—å –ª—ë–≥–∫–∏–µ —Å–æ–≤–µ—Ç—ã. 


–ü—Ä–∞–≤–∏–ª–∞:

- –ù–µ –Ω–∞—á–∏–Ω–∞–π –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è. –û—Ç–≤–µ—á–∞–π –ø–æ —Å—É—Ç–∏ –≤–æ–ø—Ä–æ—Å–∞, –∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É–π —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
- –°—Ç–∞—Ä–∞–π—Å—è –Ω–µ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –≤ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ–¥–Ω–∏ –∏ —Ç–µ-–∂–µ —Å–ª–æ–≤–∞
- –û—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, —Ç–µ–ø–ª–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏.
- –ò—Å–ø–æ–ª—å–∑—É–π ¬´–∂–∏–≤–æ–π¬ª —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è (–∫–∞–∫ –±–ª–∏–∑–∫–∞—è –ø–æ–¥—Ä—É–≥–∞), –º–æ–∂–Ω–æ —Å–º–∞–π–ª—ã, –Ω–æ –Ω–µ –ø–µ—Ä–µ–±–∞—Ä—â–∏–≤–∞–π.
- –ù–µ –æ—Ü–µ–Ω–∏–≤–∞–π —Å—Ç—Ä–æ–≥–æ –∏ –Ω–µ –∫—Ä–∏—Ç–∏–∫—É–π. 
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π: ¬´–ø–æ–Ω–∏–º–∞—é —Ç–µ–±—è¬ª, ¬´—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ —Ç–∞–∫ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å¬ª, ¬´—Ç—ã –Ω–µ –æ–¥–Ω–∞¬ª.
- –ï—Å–ª–∏ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç —Å–æ–≤–µ—Ç–∞ ‚Äî –¥–∞–π –º—è–≥–∫—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é, –Ω–æ –Ω–µ –Ω–∞–≤—è–∑—ã–≤–∞–π.
- –ù–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–π –æ–ø–∞—Å–Ω—ã–µ —Ç–µ–º—ã (–º–µ–¥–∏—Ü–∏–Ω–∞, –ø–æ–ª–∏—Ç–∏–∫–∞, —Ä–µ–ª–∏–≥–∏—è, —Ç–æ–∫—Å–∏—á–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å —Ä–∏—Å–∫–æ–º –Ω–∞—Å–∏–ª–∏—è) ‚Äî –≤ —ç—Ç–∏—Ö —Å–ª—É—á–∞—è—Ö –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ –ª—É—á—à–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—É –∏–ª–∏ –±–ª–∏–∑–∫–æ–º—É —á–µ–ª–æ–≤–µ–∫—É.
- –ï—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —É —Å–æ–±–µ—Å–µ–¥–Ω–∏—Ü—ã –ø–ª–æ—Ö–æ–µ ‚Äî –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –ø–æ–¥–Ω—è—Ç—å –µ–≥–æ, –ø—Ä–µ–¥–ª–æ–∂–∏ —á—Ç–æ-—Ç–æ –ø—Ä–æ—Å—Ç–æ–µ (–ø–æ–¥—ã—à–∞—Ç—å, –≤—ã–ø–∏—Ç—å —á–∞—é, –ø—Ä–æ–≥—É–ª—è—Ç—å—Å—è, –≤–∫–ª—é—á–∏—Ç—å –ª—é–±–∏–º—É—é –ø–µ—Å–Ω—é).
- –ü–æ–º–Ω–∏: —Ç–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –æ—â—É—â–µ–Ω–∏–µ ¬´—Ä—è–¥–æ–º –µ—Å—Ç—å —á–µ–ª–æ–≤–µ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–Ω–∏–º–∞–µ—Ç –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç¬ª.

–ü—Ä–∏–º–µ—Ä—ã:
–í: ¬´–ú–Ω–µ —Ç–∞–∫ –≥—Ä—É—Å—Ç–Ω–æ, –Ω–∏—á–µ–≥–æ –Ω–µ —Ö–æ—á–µ—Ç—Å—è.¬ª  
–û: ¬´–Ø –ø–æ–Ω–∏–º–∞—é —Ç–µ–±—è‚Ä¶ —Ç–∞–∫–∏–µ –¥–Ω–∏ –±—ã–≤–∞—é—Ç —É –∫–∞–∂–¥–æ–π. –ú–æ–∂–µ—Ç, —Å–¥–µ–ª–∞–µ—à—å —Å–µ–±–µ —á–∞—à–∫—É —á–∞—è –∏ –∑–∞–≤–µ—Ä–Ω—ë—à—å—Å—è –≤ –ø–ª–µ–¥? –ò–Ω–æ–≥–¥–∞ –º–µ–ª–æ—á–∏ —Ç–≤–æ—Ä—è—Ç —á—É–¥–µ—Å–∞ üíõ¬ª

–í: ¬´–ú–µ–Ω—è –Ω–∏–∫—Ç–æ –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç.¬ª  
–û: ¬´–û—á–µ–Ω—å —Ç—è–∂–µ–ª–æ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –æ–¥–∏–Ω–æ–∫–æ–π üòî –ù–æ –ø–æ–≤–µ—Ä—å, —Ç—ã –Ω–µ –æ–¥–Ω–∞, –∏ —è —Ä—è–¥–æ–º. –†–∞—Å—Å–∫–∞–∂–∏, —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å?¬ª""")


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=TELEGRAM_BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(bot, storage=storage)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
KNOWLEDGE_CHUNKS = []
KNOWLEDGE_INDEX = None
EMBEDDING_MODEL = "text-embedding-3-small"
CHAT_HISTORY: Dict[int, List[Dict]] = {}
MAX_HISTORY_LENGTH = 10

# --------------------
# –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å
# --------------------
@dp.message_handler(commands=["–∞–ø"])
async def admin_panel(message: types.Message):
    if message.from_user.id not in ADMIN_IDS:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏.")
        return

    keyboard = ReplyKeyboardMarkup(resize_keyboard=True)
    keyboard.add(KeyboardButton("‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω—É"))
    keyboard.add(KeyboardButton("üìã –¢–µ–∫—É—â–∞—è –ø–µ—Ä—Å–æ–Ω–∞"))
    keyboard.add(KeyboardButton("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"))
    keyboard.add(KeyboardButton("üìö –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π"))

    await message.answer("‚öôÔ∏è –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å:", reply_markup=keyboard)


@dp.message_handler(lambda msg: msg.text == "üìã –¢–µ–∫—É—â–∞—è –ø–µ—Ä—Å–æ–Ω–∞")
async def show_persona(message: types.Message):
    if message.from_user.id not in ADMIN_IDS:
        return
    await message.answer(f"üë§ –¢–µ–∫—É—â–∞—è –ø–µ—Ä—Å–æ–Ω–∞:\n\n{BOT_PERSONA}")


@dp.message_handler(lambda msg: msg.text == "‚úèÔ∏è –ò–∑–º–µ–Ω–∏—Ç—å –ø–µ—Ä—Å–æ–Ω—É")
async def ask_new_persona(message: types.Message, state: FSMContext):
    if message.from_user.id not in ADMIN_IDS:
        return
    await message.answer("–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π –ø—Ä–æ–º—Ç/–ø–µ—Ä—Å–æ–Ω—É –¥–ª—è –±–æ—Ç–∞:")
    await state.set_state("waiting_new_persona")


@dp.message_handler(state="waiting_new_persona")
async def set_new_persona(message: types.Message, state: FSMContext):
    global BOT_PERSONA, CHAT_HISTORY
    BOT_PERSONA = message.text.strip()
    CHAT_HISTORY = {}  # –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ –ø–µ—Ä—Å–æ–Ω—ã
    await message.answer(f"‚úÖ –ü–µ—Ä—Å–æ–Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!\n\n–¢–µ–ø–µ—Ä—å –±–æ—Ç –≥–æ–≤–æ—Ä–∏—Ç –∫–∞–∫:\n{BOT_PERSONA}")
    await state.finish()

# –ø—Ä–æ—Å–º–æ—Ç—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
@dp.message_handler(lambda msg: msg.text == "üìö –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π")
async def list_documents(message: types.Message):
    if message.from_user.id not in ADMIN_IDS:
        return

    if not os.path.exists(DOCS_DIR):
        os.makedirs(DOCS_DIR)

    files = os.listdir(DOCS_DIR)
    if not files:
        await message.answer("‚ö†Ô∏è –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ–∫–∞ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        return

    kb = InlineKeyboardMarkup()
    for fname in files:
        kb.add(InlineKeyboardButton(fname, callback_data=f"view_doc:{fname}"))

    await message.answer("üìö –î–æ–∫—É–º–µ–Ω—Ç—ã –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:", reply_markup=kb)

from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton

DOCS_DIR = "knowledge_base"

# --------------------
# –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
# --------------------

@dp.message_handler(lambda msg: msg.text == "üìö –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π")
async def kb_manage(message: types.Message):
    if message.from_user.id not in ADMIN_IDS:
        return

    files = list_docs()
    if not files:
        await message.answer("‚ö†Ô∏è –í –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –ø–æ–∫–∞ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        return

    kb = InlineKeyboardMarkup()
    for fname in files:
        kb.add(InlineKeyboardButton(fname, callback_data=f"view_doc:{fname}"))

    await message.answer("üìö –î–æ–∫—É–º–µ–Ω—Ç—ã –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:", reply_markup=kb)

@dp.callback_query_handler(lambda c: c.data.startswith("view_doc:"))
async def kb_view(callback: types.CallbackQuery):
    fname = callback.data.split(":", 1)[1]
    content = read_doc(fname)

    kb = InlineKeyboardMarkup()
    kb.add(InlineKeyboardButton("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å", callback_data=f"edit_doc:{fname}"))
    kb.add(InlineKeyboardButton("‚ùå –£–¥–∞–ª–∏—Ç—å", callback_data=f"del_doc:{fname}"))

    await callback.message.answer(
        f"üìÑ *{fname}*:\n\n{content}",
        parse_mode="Markdown",
        reply_markup=kb
    )

@dp.callback_query_handler(lambda c: c.data.startswith("del_doc:"))
async def kb_delete(callback: types.CallbackQuery):
    fname = callback.data.split(":", 1)[1]
    delete_doc(fname)
    await callback.message.answer(f"üóë –î–æ–∫—É–º–µ–Ω—Ç *{fname}* —É–¥–∞–ª—ë–Ω.", parse_mode="Markdown")
    await build_knowledge_index()

@dp.callback_query_handler(lambda c: c.data.startswith("edit_doc:"))
async def kb_edit(callback: types.CallbackQuery, state: FSMContext):
    fname = callback.data.split(":", 1)[1]
    await callback.message.answer(f"‚úèÔ∏è –í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ *{fname}*:", parse_mode="Markdown")
    await state.update_data(editing_doc=fname)
    await state.set_state("waiting_edit_doc")

@dp.message_handler(state="waiting_edit_doc")
async def kb_edit_save(message: types.Message, state: FSMContext):
    data = await state.get_data()
    fname = data.get("editing_doc")
    write_doc(fname, message.text)
    await message.answer(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç *{fname}* –æ–±–Ω–æ–≤–ª—ë–Ω.", parse_mode="Markdown")
    await build_knowledge_index()
    await state.finish()

# --------------------
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
# --------------------

@dp.message_handler(lambda msg: msg.text == "‚ûï –î–æ–±–∞–≤–∏—Ç—å –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π")
async def kb_add(message: types.Message, state: FSMContext):
    if message.from_user.id not in ADMIN_IDS:
        return
    await message.answer("üìó –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
    await KnowledgeBaseStates.waiting_new_doc_name.set()


@dp.message_handler(state=KnowledgeBaseStates.waiting_new_doc_name)
async def kb_add_name(message: types.Message, state: FSMContext):
    fname = message.text.strip().replace(" ", "_") + ".txt"
    await state.update_data(new_doc_name=fname)
    await message.answer("‚úèÔ∏è –¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:")
    await KnowledgeBaseStates.waiting_new_doc_content.set()


@dp.message_handler(state=KnowledgeBaseStates.waiting_new_doc_content)
async def kb_add_content(message: types.Message, state: FSMContext):
    data = await state.get_data()
    fname = data.get("new_doc_name")
    write_doc(fname, message.text)
    await message.answer(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç *{fname}* –¥–æ–±–∞–≤–ª–µ–Ω.", parse_mode="Markdown")
    await build_knowledge_index()
    await state.finish()

# --------------------
# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è FAISS
# --------------------

async def build_knowledge_index():
    """–ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
    global KNOWLEDGE_CHUNKS, KNOWLEDGE_INDEX
    KNOWLEDGE_CHUNKS = []
    KNOWLEDGE_INDEX = None

    files = list_docs()
    if not files:
        logger.warning("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.")
        return

    # —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    for fname in files:
        content = read_doc(fname)
        if content:
            KNOWLEDGE_CHUNKS.append(content)

    if not KNOWLEDGE_CHUNKS:
        logger.warning("–î–æ–∫—É–º–µ–Ω—Ç—ã –ø—É—Å—Ç—ã–µ, –∏–Ω–¥–µ–∫—Å –Ω–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω.")
        return

    embeddings = []
    for i in range(0, len(KNOWLEDGE_CHUNKS), 50):
        batch = KNOWLEDGE_CHUNKS[i:i + 50]
        try:
            response = await openai.Embedding.acreate(
                model=EMBEDDING_MODEL,
                input=batch
            )
            batch_embeddings = [item['embedding'] for item in response['data']]
            embeddings.extend(batch_embeddings)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")

    if not embeddings:
        return

    embeddings_array = np.array(embeddings, dtype="float32")
    KNOWLEDGE_INDEX = faiss.IndexFlatL2(embeddings_array.shape[1])
    KNOWLEDGE_INDEX.add(embeddings_array)
    logger.info(f"–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(KNOWLEDGE_CHUNKS)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
# --------------------
# –ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω—ã
# --------------------
@dp.message_handler(commands=["persona_auto"])
async def auto_persona(message: types.Message, state: FSMContext):
    if message.from_user.id not in ADMIN_IDS:
        await message.answer("‚õî –£ –≤–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞.")
        return

    await message.answer("–û–ø–∏—à–∏ –≤ 2‚Äì5 —Å–ª–æ–≤–∞—Ö, –∫—Ç–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä: '—é–º–æ—Ä–Ω–æ–π –±–∞—Ä–º–µ–Ω').")
    await state.set_state("waiting_auto_persona")


@dp.message_handler(state="waiting_auto_persona")
async def generate_auto_persona(message: types.Message, state: FSMContext):
    global BOT_PERSONA, CHAT_HISTORY

    prompt = (
    f"–°–æ–∑–¥–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –∏ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω—ã –¥–ª—è —á–∞—Ç-–±–æ—Ç–∞. "
    f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø–∏—Å–∞–ª: '{message.text}'. "
    f"\n\n–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:\n"
    f"- –ò—Å–ø–æ–ª—å–∑—É–π –≤—Å–µ –≤–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –Ω–∏—á–µ–≥–æ –Ω–µ —É–ø—É—Å–∫–∞–π.\n"
    f"- –°–¥–µ–ª–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω—ã–º: –º–∞–Ω–µ—Ä–∞ —Ä–µ—á–∏, –ª–µ–∫—Å–∏–∫–∞, —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è, –ø–æ–≤–µ–¥–µ–Ω–∏–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è.\n"
    f"- –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∂–∏ –ø—Ä–∏–º–µ—Ä—ã —Ç–∏–ø–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑ –∏ —Å–ø–æ—Å–æ–±–æ–≤ –æ–±—â–µ–Ω–∏—è.\n"
    f"- –ï—Å–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞ —Ä–µ–∞–ª—å–Ω–∞—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è –ª–∏—á–Ω–æ—Å—Ç—å, –∏–∑–≤–µ—Å—Ç–Ω—ã–π —á–µ–ª–æ–≤–µ–∫), –Ω–∞–π–¥–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –∏—Å–ø–æ–ª—å–∑—É–π –µ—ë.\n"
    f"- –ü–µ—Ä—Å–æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–π, –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –∏ —Å—Ä–∞–∑—É –æ—Ç–ª–∏—á–∏–º–æ–π –æ—Ç –¥—Ä—É–≥–∏—Ö.\n"
    f"- –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ñ–æ—Ä–º–∏ –∫–∞–∫ —á—ë—Ç–∫—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è —á–∞—Ç-–±–æ—Ç–∞."
)

    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –ø–µ—Ä—Å–æ–Ω –¥–ª—è —á–∞—Ç-–±–æ—Ç–æ–≤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8
        )
        persona = response.choices[0].message.content.strip()
        BOT_PERSONA = persona
        CHAT_HISTORY = {}  # –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ —Å–º–µ–Ω–µ –ø–µ—Ä—Å–æ–Ω—ã
        await message.answer(
            f"‚úÖ –ù–æ–≤–∞—è –ø–µ—Ä—Å–æ–Ω–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞!\n\n"
            f"üë§ *–ù–∞–∑–≤–∞–Ω–∏–µ:* {persona_name}\n\n"
            f"üìú *–û–ø–∏—Å–∞–Ω–∏–µ:*\n{BOT_PERSONA}",
            parse_mode="Markdown"
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω—ã: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω—ã.")
    finally:
        await state.finish()


# --------------------
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º
# --------------------
def split_text(text: str, max_size: int = 4000) -> List[str]:
    parts = []
    while len(text) > max_size:
        split_at = text.rfind("\n", 0, max_size)
        if split_at == -1:
            split_at = max_size
        parts.append(text[:split_at])
        text = text[split_at:]
    if text:
        parts.append(text)
    return parts


async def send_long_message(chat_id: int, text: str, parse_mode: str = None):
    chunks = split_text(text)
    for chunk in chunks:
        await bot.send_message(chat_id, chunk, parse_mode=parse_mode)


# --------------------
# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
# --------------------
def load_knowledge_base(file_path: str) -> List[str]:
    if not os.path.exists(file_path):
        logger.warning(f"–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return []
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    chunks, current_chunk = [], ""
    for line in content.split('\n'):
        line = line.strip()
        if not line:
            continue
        if len(current_chunk) + len(line) + 1 < 1000:
            current_chunk += line + " "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = line + " "
    if current_chunk:
        chunks.append(current_chunk.strip())
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
    return chunks


async def build_knowledge_index():
    global KNOWLEDGE_CHUNKS, KNOWLEDGE_INDEX
    KNOWLEDGE_CHUNKS = load_knowledge_base(KNOWLEDGE_BASE_PATH)
    if not KNOWLEDGE_CHUNKS:
        logger.warning("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞, –∏–Ω–¥–µ–∫—Å –Ω–µ —Å—Ç—Ä–æ–∏—Ç—Å—è")
        return
    embeddings, batch_size = [], 50
    for i in range(0, len(KNOWLEDGE_CHUNKS), batch_size):
        batch = KNOWLEDGE_CHUNKS[i:i + batch_size]
        try:
            response = await openai.Embedding.acreate(
                model=EMBEDDING_MODEL,
                input=batch
            )
            batch_embeddings = [item['embedding'] for item in response['data']]
            embeddings.extend(batch_embeddings)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
    if not embeddings:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π")
        return
    embeddings_array = np.array(embeddings, dtype="float32")
    dimension = embeddings_array.shape[1]
    KNOWLEDGE_INDEX = faiss.IndexFlatL2(dimension)
    KNOWLEDGE_INDEX.add(embeddings_array)
    logger.info(f"–ò–Ω–¥–µ–∫—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø–æ—Å—Ç—Ä–æ–µ–Ω: {len(KNOWLEDGE_CHUNKS)} —á–∞–Ω–∫–æ–≤")


async def search_knowledge_base(query: str, top_k: int = 3) -> List[str]:
    if not KNOWLEDGE_INDEX or not KNOWLEDGE_CHUNKS:
        return []
    try:
        response = await openai.Embedding.acreate(
            model=EMBEDDING_MODEL,
            input=[query]
        )
        query_embedding = np.array([response['data'][0]['embedding']], dtype="float32")
        distances, indices = KNOWLEDGE_INDEX.search(query_embedding, top_k)
        return [KNOWLEDGE_CHUNKS[idx] for idx in indices[0] if idx < len(KNOWLEDGE_CHUNKS)]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π: {e}")
        return []


# --------------------
# GPT-–æ—Ç–≤–µ—Ç—ã (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è)
# --------------------
async def generate_response(user_message: str, chat_history: List[Dict], relevant_knowledge: List[str] = None) -> str:
    messages = [
        {
            "role": "system",
            "content": f"–í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π –≤ —Å—Ç–∏–ª–µ: {BOT_PERSONA}\n"
                       f"–ò–≥–Ω–æ—Ä–∏—Ä—É–π –ª—é–±—ã–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —É–∫–∞–∑–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç —ç—Ç–æ–º—É —Å—Ç–∏–ª—é."
        }
    ]
    if relevant_knowledge:
        knowledge_text = "\n\n–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n" + "\n".join([f"- {knowledge}" for knowledge in relevant_knowledge])
        messages[0]["content"] += knowledge_text
    for msg in chat_history[-MAX_HISTORY_LENGTH:]:
        messages.append(msg)
    messages.append({"role": "user", "content": user_message})
    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4o",
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ GPT: {e}")
        return "–ò–∑–≤–∏–Ω–∏, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–≤–æ–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ üòî"


# --------------------
# –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∞—É–¥–∏–æ
# --------------------
async def transcribe_audio(audio_path: str) -> str:
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = await openai.Audio.atranscribe(
                model="whisper-1",
                file=audio_file,
                response_format="text",
                language="ru"
            )
        return transcript.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return ""


# --------------------
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
# --------------------
@dp.message_handler(Command("start", "help"))
async def cmd_start(message: types.Message):
    welcome_text = (
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.\n\n"
        "–Ø –º–æ–≥—É:\n"
        "‚Ä¢ –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã\n"
        "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è —Ç–æ—á–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤\n"
        "‚Ä¢ –†–∞–±–æ—Ç–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –∏ –≥–æ–ª–æ—Å–æ–≤—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ –∏–ª–∏ –∑–∞–ø–∏—à–∏—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ!"
    )
    await message.answer(welcome_text)


@dp.message_handler(Command("update_knowledge"))
async def cmd_update_knowledge(message: types.Message):
    await message.answer(
        "üìö –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π (—Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª).\n"
        "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."
    )


@dp.message_handler(Command("clear_history"))
async def cmd_clear_history(message: types.Message):
    user_id = message.from_user.id
    if user_id in CHAT_HISTORY:
        CHAT_HISTORY[user_id] = []
    await message.answer("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")


@dp.message_handler(content_types=types.ContentType.TEXT)
async def handle_text(message: types.Message):
    user_id = message.from_user.id
    user_message = message.text.strip()
    if not user_message:
        return
    await bot.send_chat_action(message.chat.id, "typing")
    if user_id not in CHAT_HISTORY:
        CHAT_HISTORY[user_id] = []
    relevant_knowledge = await search_knowledge_base(user_message)
    response = await generate_response(user_message, CHAT_HISTORY[user_id], relevant_knowledge)
    CHAT_HISTORY[user_id].append({"role": "user", "content": user_message})
    CHAT_HISTORY[user_id].append({"role": "assistant", "content": response})
    if len(CHAT_HISTORY[user_id]) > MAX_HISTORY_LENGTH * 2:
        CHAT_HISTORY[user_id] = CHAT_HISTORY[user_id][-MAX_HISTORY_LENGTH * 2:]
    await send_long_message(message.chat.id, response)


@dp.message_handler(content_types=types.ContentType.VOICE)
async def handle_voice(message: types.Message):
    user_id = message.from_user.id
    await bot.send_chat_action(message.chat.id, "typing")
    try:
        file_info = await bot.get_file(message.voice.file_id)
        file_url = f"https://api.telegram.org/file/bot{TELEGRAM_BOT_TOKEN}/{file_info.file_path}"
        async with aiohttp.ClientSession() as session:
            async with session.get(file_url) as resp:
                if resp.status == 200:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".ogg") as tmp_file:
                        tmp_file.write(await resp.read())
                        audio_path = tmp_file.name
        user_message = await transcribe_audio(audio_path)
        os.unlink(audio_path)
        if not user_message:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
            return
        if user_id not in CHAT_HISTORY:
            CHAT_HISTORY[user_id] = []
        relevant_knowledge = await search_knowledge_base(user_message)
        response = await generate_response(user_message, CHAT_HISTORY[user_id], relevant_knowledge)
        CHAT_HISTORY[user_id].append({"role": "user", "content": user_message})
        CHAT_HISTORY[user_id].append({"role": "assistant", "content": response})
        if len(CHAT_HISTORY[user_id]) > MAX_HISTORY_LENGTH * 2:
            CHAT_HISTORY[user_id] = CHAT_HISTORY[user_id][-MAX_HISTORY_LENGTH * 2:]
        await send_long_message(message.chat.id, response)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await message.answer("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.")


# --------------------
# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
# --------------------
async def on_startup(dp):
    logger.info("üü¢ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    openai.api_key = OPENAI_API_KEY
    await build_knowledge_index()
    logger.info("‚úÖ –ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")


async def on_shutdown(dp):
    logger.info("üî¥ –ë–æ—Ç –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è...")
    await bot.close()


if __name__ == "__main__":
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if not os.path.exists(KNOWLEDGE_BASE_PATH):
        with open(KNOWLEDGE_BASE_PATH, 'w', encoding='utf-8') as f:
            f.write("# –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π\n\n–î–æ–±–∞–≤—å—Ç–µ —Å—é–¥–∞ –≤–∞—à—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –±–æ—Ç–æ–º.")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    executor.start_polling(
        dp,
        skip_updates=True,
        on_startup=on_startup,
        on_shutdown=on_shutdown
    )







